{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма исходных данных: (320, 10, 246)\n",
      "Форма данных после усреднения: (320, 246)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\AppData\\Local\\Temp\\ipykernel_18472\\3124052259.py:10: RuntimeWarning: Mean of empty slice\n",
      "  averaged_data = np.nanmean(data, axis=1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Загрузка данных из файла .npy\n",
    "data = np.load('ihb.npy')  # Замените 'data.npy' на путь к вашему файлу\n",
    "\n",
    "# Проверяем форму данных\n",
    "print(f\"Форма исходных данных: {data.shape}\")  # Должно быть [320, 10, 246]\n",
    "\n",
    "# Усредняем по второму измерению (по временным шагам), игнорируя NaN\n",
    "averaged_data = np.nanmean(data, axis=1)\n",
    "\n",
    "# Проверяем форму после усреднения\n",
    "print(f\"Форма данных после усреднения: {averaged_data.shape}\")  # Должно быть [320, 246]\n",
    "\n",
    "# Сохраняем преобразованные данные, если необходимо\n",
    "np.save('averaged_data.npy', averaged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма train_x: (51040, 2, 246)\n",
      "Форма train_y: (51040,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "# Загружаем усредненные данные (после предыдущего шага)\n",
    "averaged_data = np.load('averaged_data.npy')  # Форма данных: [320, 246]\n",
    "\n",
    "# Количество субъектов и представлений\n",
    "num_subjects = 20\n",
    "representations_per_subject = 16\n",
    "\n",
    "# Генерация всех возможных пар индексов (combinations даёт все возможные пары)\n",
    "pairs = list(combinations(range(averaged_data.shape[0]), 2))\n",
    "\n",
    "# Создание массива признаков для пар объектов\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "for pair in pairs:\n",
    "    idx1, idx2 = pair\n",
    "    \n",
    "    # Добавляем признаки обеих пар в массив\n",
    "    train_x.append([averaged_data[idx1], averaged_data[idx2]])\n",
    "    \n",
    "    # Определяем метку: 1, если оба объекта принадлежат одному субъекту, 0 — если нет\n",
    "    label = 1 if idx1 // representations_per_subject == idx2 // representations_per_subject else 0\n",
    "    train_y.append(label)\n",
    "\n",
    "# Преобразуем train_x и train_y в numpy массивы для дальнейшего использования\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "# Проверяем формы данных\n",
    "print(f\"Форма train_x: {train_x.shape}\")  # Ожидаемая форма: [num_pairs, 2, 246]\n",
    "print(f\"Форма train_y: {train_y.shape}\")  # Ожидаемая форма: [num_pairs]\n",
    "\n",
    "# Сохранение данных, если необходимо\n",
    "np.save('train_x.npy', train_x)\n",
    "np.save('train_y.npy', train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверка пары (0, 15):\n",
      "Пациент 1: 0, Пациент 2: 0\n",
      "Ожидаемая метка: 1, Фактическая метка: 1\n",
      "Проверка пары (17, 23):\n",
      "Пациент 1: 1, Пациент 2: 1\n",
      "Ожидаемая метка: 1, Фактическая метка: 1\n"
     ]
    }
   ],
   "source": [
    "# Пример ручной проверки пары\n",
    "def manual_check_pair(idx1, idx2, train_x, train_y):\n",
    "    # Определяем пациентов для объектов\n",
    "    patient1 = idx1 // 16\n",
    "    patient2 = idx2 // 16\n",
    "\n",
    "    # Проверяем бинарную метку\n",
    "    correct_label = 1 if patient1 == patient2 else 0\n",
    "    actual_label = train_y[list(combinations(range(320), 2)).index((idx1, idx2))]\n",
    "\n",
    "    print(f\"Проверка пары ({idx1}, {idx2}):\")\n",
    "    print(f\"Пациент 1: {patient1}, Пациент 2: {patient2}\")\n",
    "    print(f\"Ожидаемая метка: {correct_label}, Фактическая метка: {actual_label}\")\n",
    "\n",
    "# Пример проверки: проверяем, принадлежат ли объекты 0 и 15 одному пациенту\n",
    "manual_check_pair(0, 15, train_x, train_y)\n",
    "\n",
    "# Пример проверки: проверяем, принадлежат ли объекты 0 и 20 разным пациентам\n",
    "manual_check_pair(17, 23, train_x, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "# Загрузка данных\n",
    "train_x = np.load('train_x.npy')  # [num_pairs, 2, 246]\n",
    "train_y = np.load('train_y.npy')  # [num_pairs]\n",
    "\n",
    "# Заменим NaN на нули в train_x\n",
    "train_x = np.nan_to_num(train_x, nan=0.0)  # Заменяем NaN на 0.0\n",
    "# Если хотите заменить NaN на средние значения по признакам:\n",
    "# mean_vals = np.nanmean(train_x, axis=0)  # Считаем средние значения по каждому признаку\n",
    "# np.where(np.isnan(train_x), mean_vals, train_x)  # Заменяем NaN на средние значения\n",
    "# Преобразование данных в тензоры PyTorch\n",
    "train_x_tensor = torch.tensor(train_x, dtype=torch.float32)  # Признаки пар\n",
    "train_y_tensor = torch.tensor(train_y, dtype=torch.float32)  # Метки (0 или 1)\n",
    "\n",
    "# Соединяем два набора признаков в один тензор для каждой пары (вектор размером 492)\n",
    "train_x_combined = torch.cat((train_x_tensor[:, 0, :], train_x_tensor[:, 1, :]), dim=1)\n",
    "\n",
    "# Создание DataLoader для удобной подачи данных в нейронную сеть\n",
    "dataset = TensorDataset(train_x_combined, train_y_tensor)\n",
    "train_size = int(0.8 * len(dataset))  # 80% данных для тренировки\n",
    "test_size = len(dataset) - train_size  # 20% данных для теста\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В данных train_x нет NaN-значений\n",
      "В данных train_y нет NaN-значений\n"
     ]
    }
   ],
   "source": [
    "# Проверка наличия NaN в train_x\n",
    "if torch.isnan(train_x_tensor).any():\n",
    "    print(\"В данных train_x есть NaN-значения\")\n",
    "else:\n",
    "    print(\"В данных train_x нет NaN-значений\")\n",
    "\n",
    "# Проверка наличия NaN в train_y\n",
    "if torch.isnan(train_y_tensor).any():\n",
    "    print(\"В данных train_y есть NaN-значения\")\n",
    "else:\n",
    "    print(\"В данных train_y нет NaN-значений\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение архитектуры нейронной сети\n",
    "class MatchingNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MatchingNetwork, self).__init__()\n",
    "        # Входной слой на 492 нейрона\n",
    "        self.fc1 = nn.Linear(246*2, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "        self.relu = nn.LeakyReLU(negative_slope=0.01)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Прямое распространение через сеть\n",
    "        x = self.relu(self.fc1(x))  # Первый полносвязанный слой\n",
    "        x = self.relu(self.fc2(x))  # Второй полносвязанный слой\n",
    "        x = self.fc3(x)  # Выходной слой с сигмоидальной активацией\n",
    "        return x\n",
    "\n",
    "# Инициализируем модель\n",
    "model = MatchingNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция потерь — бинарная кросс-энтропия\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# Оптимизатор — Adam\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха [1/10], Потери: 0.18641902305854363\n",
      "Эпоха [2/10], Потери: 0.1690491731731122\n",
      "Эпоха [3/10], Потери: 0.15699812350648698\n",
      "Эпоха [4/10], Потери: 0.14288729506283473\n",
      "Эпоха [5/10], Потери: 0.12423709787842219\n",
      "Эпоха [6/10], Потери: 0.10438773821676811\n",
      "Эпоха [7/10], Потери: 0.08565785772159601\n",
      "Эпоха [8/10], Потери: 0.06868122605389954\n",
      "Эпоха [9/10], Потери: 0.0555355278435409\n",
      "Эпоха [10/10], Потери: 0.04707531487272295\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            # Прямой проход (forward)\n",
    "            outputs = model(inputs).squeeze()  # Убираем лишние размеры\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Ограничение норм\n",
    "\n",
    "            # Так как последний слой уже содержит Sigmoid, можем сразу считать потери\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Обратное распространение (backward) и шаг оптимизации\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f\"Эпоха [{epoch+1}/{num_epochs}], Потери: {running_loss / len(train_loader)}\")\n",
    "\n",
    "# Обучаем модель\n",
    "train_model(model, train_dataset, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 4.67%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.046728056426332286"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создание DataLoader для тренировки и теста\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()  # Переводим модель в режим оценки (без обновления градиентов)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs).squeeze()\n",
    "            predictions = (outputs > 0.5).float()  # Преобразуем вероятности в бинарные метки (0 или 1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "    return accuracy\n",
    "\n",
    "# Запуск теста:\n",
    "test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Реальная метка (0 или 1, для того, что принадлежат ли они одному человеку): True\n",
      "Предсказанная метка модели: tensor([[nan]])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"D:\\VS CODE\\Works\\YandexContest\\\\model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
